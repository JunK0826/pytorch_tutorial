{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 10/100, cost: 0.4955716133117676\n",
      "epochs: 20/100, cost: 0.45466527342796326\n",
      "epochs: 30/100, cost: 0.38243213295936584\n",
      "epochs: 40/100, cost: 0.3243464231491089\n",
      "epochs: 50/100, cost: 0.2732938230037689\n",
      "epochs: 60/100, cost: 0.22697977721691132\n",
      "epochs: 70/100, cost: 0.18711109459400177\n",
      "epochs: 80/100, cost: 0.16004030406475067\n",
      "epochs: 90/100, cost: 0.14572511613368988\n",
      "epochs: 100/100, cost: 0.13564400374889374\n",
      "tensor([[0.0245],\n",
      "        [0.1484],\n",
      "        [0.2770],\n",
      "        [0.7954],\n",
      "        [0.9484],\n",
      "        [0.9834]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n"
     ]
    }
   ],
   "source": [
    "# mothod 1.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(777)\n",
    "\n",
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "W = torch.zeros((2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "    # hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))\n",
    "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "\n",
    "    # losses = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis))\n",
    "    # cost = losses.mean()\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epochs: {epoch}/{nb_epochs}, cost: {cost.item()}')\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "print(hypothesis)\n",
    "prediction = (hypothesis >= 0.5).type(torch.FloatTensor)\n",
    "print(prediction)\n",
    "correct_prediction = prediction == y_train\n",
    "print(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 10/100, cost: 1.0310767889022827\n",
      "epochs: 20/100, cost: 0.6099081635475159\n",
      "epochs: 30/100, cost: 0.507769763469696\n",
      "epochs: 40/100, cost: 0.42099571228027344\n",
      "epochs: 50/100, cost: 0.33837273716926575\n",
      "epochs: 60/100, cost: 0.26213324069976807\n",
      "epochs: 70/100, cost: 0.20035725831985474\n",
      "epochs: 80/100, cost: 0.16357332468032837\n",
      "epochs: 90/100, cost: 0.14729078114032745\n",
      "epochs: 100/100, cost: 0.13692478835582733\n",
      "tensor([[0.0249],\n",
      "        [0.1484],\n",
      "        [0.2790],\n",
      "        [0.7932],\n",
      "        [0.9473],\n",
      "        [0.9831]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n"
     ]
    }
   ],
   "source": [
    "# method 2.\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "model = BinaryClassifier()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epochs: {epoch}/{nb_epochs}, cost: {cost.item()}')\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "hypothesis = model(x_train)\n",
    "print(hypothesis)\n",
    "prediction = (hypothesis >= 0.5).type(torch.FloatTensor)\n",
    "print(prediction)\n",
    "correct_prediction = prediction.float() == y_train\n",
    "print(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
