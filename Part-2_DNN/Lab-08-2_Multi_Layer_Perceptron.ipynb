{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.6931471824645996\n",
      "step: 1000, cost: 0.6931471824645996\n",
      "step: 2000, cost: 0.6931471824645996\n",
      "step: 3000, cost: 0.6931471824645996\n",
      "step: 4000, cost: 0.6931471824645996\n",
      "step: 5000, cost: 0.6931471824645996\n",
      "step: 6000, cost: 0.6931471824645996\n",
      "step: 7000, cost: 0.6931471824645996\n",
      "step: 8000, cost: 0.6931471824645996\n",
      "step: 9000, cost: 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# do not working\n",
    "import torch\n",
    "x = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "w1 = torch.Tensor(2, 2)\n",
    "b1 = torch.Tensor(2)\n",
    "w2 = torch.Tensor(2, 1)\n",
    "b2 = torch.Tensor(1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "learning_rate = 1\n",
    "for step in range(10000):\n",
    "    # model\n",
    "    l1 = x.matmul(w1) + b1\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = a1.matmul(w2) + b2\n",
    "    pred = sigmoid(l2)\n",
    "\n",
    "\n",
    "    # binary cross entropy loss\n",
    "    losses = -(y * torch.log(pred) + (1 - y) * torch.log(1 - pred))\n",
    "    cost = losses.mean()\n",
    "\n",
    "    # back propagation SGD\n",
    "    d_pred = (pred - y) / (pred * (1.0 - pred) + 1e-7)\n",
    "\n",
    "    d_l2 = d_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2)\n",
    "\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(x, 0, 1), d_b1)\n",
    "\n",
    "    # weight update\n",
    "    w1 = w1 - (learning_rate * d_w1)\n",
    "    b1 = b1 - (learning_rate * torch.mean(d_b1, 0))\n",
    "    w2 = w2 - (learning_rate * d_w2)\n",
    "    b2 = b2 - (learning_rate * torch.mean(d_b2, 0))\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f'step: {step}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.712634801864624\n",
      "step: 1000, cost: 0.0328436940908432\n",
      "step: 2000, cost: 0.007596956100314856\n",
      "step: 3000, cost: 0.004227927885949612\n",
      "step: 4000, cost: 0.0029185202438384295\n",
      "step: 5000, cost: 0.00222511263564229\n",
      "step: 6000, cost: 0.0017964745638892055\n",
      "step: 7000, cost: 0.0015056406846269965\n",
      "step: 8000, cost: 0.0012954158009961247\n",
      "step: 9000, cost: 0.001136478502303362\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "for step in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    hypothesis = model(x)\n",
    "    cost = criterion(hypothesis, y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 1000 == 0:\n",
    "        print(f'step: {step}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 0.6960805058479309\n",
      "step: 1000, cost: 0.6931338310241699\n",
      "step: 2000, cost: 0.693114161491394\n",
      "step: 3000, cost: 0.6930643320083618\n",
      "step: 4000, cost: 0.6927794218063354\n",
      "step: 5000, cost: 0.03718432039022446\n",
      "step: 6000, cost: 0.000736469286493957\n",
      "step: 7000, cost: 0.00034019301529042423\n",
      "step: 8000, cost: 0.00021725319675169885\n",
      "step: 9000, cost: 0.0001583823177497834\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "linear1 = torch.nn.Linear(2, 10, bias=True)\n",
    "linear2 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear3 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear4 = torch.nn.Linear(10, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "for step in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    hypothesis = model(x)\n",
    "    cost = criterion(hypothesis, y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 1000 == 0:\n",
    "        print(f'step: {step}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
